{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10BKigKLhKvg"
      },
      "source": [
        "# Code 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Icqp12_YhYrH",
        "outputId": "a2e8ef16-1f7b-42cf-fbe8-d23bde769c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=9d9a8ea6040761d192c47497ce15c823477c97a5fe34fa66c027ec1caadc4791\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ],
      "source": [
        "pip install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pVpbncHhlvm",
        "outputId": "18b70ef4-18d8-47e7-9462-2a651065107f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/VIDEOUSED.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp42isom\n",
            "  Duration: 00:05:05.18, start: 0.000000, bitrate: 246 kb/s\n",
            "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 114 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc (default)\n",
            "    Metadata:\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
            "    Metadata:\n",
            "      vendor_id       : [0][0][0][0]\n",
            "File 'test_aud.wav' already exists. Overwrite? [y/N] Not overwriting - exiting\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "command = \"ffmpeg -i /content/VIDEOUSED.mp4 -ab 160k -ar 44100 -vn test_aud.wav\"\n",
        "try:\n",
        "    output = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT)\n",
        "    print(\"FFmpeg Output:\", output.decode())\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(\"Error:\", e.output.decode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD2pcD4JhpLo",
        "outputId": "91a918ed-acd9-47e6-9ffb-464b4f3c788c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pipwin in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from pipwin) (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pipwin) (2.31.0)\n",
            "Requirement already satisfied: pyprind in /usr/local/lib/python3.10/dist-packages (from pipwin) (2.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pipwin) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from pipwin) (4.12.3)\n",
            "Requirement already satisfied: js2py in /usr/local/lib/python3.10/dist-packages (from pipwin) (0.74)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pipwin) (23.2)\n",
            "Requirement already satisfied: pySmartDL>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pipwin) (1.3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9.0->pipwin) (2.5)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py->pipwin) (5.2)\n",
            "Requirement already satisfied: pyjsparser>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from js2py->pipwin) (2.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pipwin) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pipwin) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pipwin) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pipwin) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pipwin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-58R2hLhpqy",
        "outputId": "8232c770-37fa-4eec-f613-cb8fc0fc92fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.1\n"
          ]
        }
      ],
      "source": [
        "pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY5weoahhrlo",
        "outputId": "c758d9f9-5b43-4f0f-9f78-eda019f10a3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text from audio:  welcome to another speak English with me video most of you guys already know how this works for the new people here I'll explain but first of all thank you for joining us so you will basically speak English with me we will have a dialogue where one line will be mine and the next one will be yours I'm going to say my line and then you will read your line from the screen out loud as if you were answering me and then by server so today's dialogue will take place in a store it'll be a dialogue between a customer and a cashier at a checkout counter we all shop and here in the US cashiers always make small talk with customers so if you're planning on traveling here it'll be useful to practice it Hi how are you today I'm doing well thank you how about you I'm good thanks just grabbing a few things for the weekend sounds great did you find everything you were looking for yes I did but I have a question about the price of this item it's showing up as a different price than what I saw on the Shelf sure I can help you with that which item is it is this pack of gum let me take a look oh you're right it looks like the wrong price tag was placed on this item I apologize for the confusion I'll make sure to fix it the correct price for this game is 399 thank you for letting me know I appreciate your help of course no problem will that be all for you today yes that's everything great you're total comes to 2473 how would you like to pay I'll pay with my credit card all right you're all set thank you for shopping with us today and have a great weekend thanks you too okay let's get into it I will start Hi how are you today I'm good thanks just grabbing a few things for the weekend yes I did but I have a question about the price of this item it's showing up as a different price than what I saw on the Shelf is this pack I'm gone thank you for letting me know I appreciate your help yes that's everything okay with my credit card thanks you too all right great job and now we switch you go first I'm doing well thank you how about you sounds great did you find everything you were looking for sure I can help you with that which item is it let me take a look oh you're right it looks like the wrong price tag was placed on this item I apologize for the confusion I'll make sure to fix it the correct price for this gum is 399 of course no problem will that be all for you today great you're total comes to 2473 how would you like to pay all right you're all set thank you for shopping with us today and have a great weekend all right I hope you guys enjoyed practicing your speaking with me and I hope to see you in the next video bye\n"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "wav_file = \"test_aud.wav\"\n",
        "\n",
        "# Initialize the recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Load the WAV file\n",
        "with sr.AudioFile(wav_file) as source:\n",
        "    audio_data = recognizer.record(source)\n",
        "\n",
        "# Convert the audio to text\n",
        "try:\n",
        "    text = recognizer.recognize_google(audio_data)\n",
        "    print(\"Text from audio: \", text)\n",
        "except sr.UnknownValueError:\n",
        "    print(\"Could not understand audio\")\n",
        "except sr.RequestError as e:\n",
        "    print(f\"Error with the request: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwOqobzihuYR",
        "outputId": "1be56212-3559-4b55-ab8c-239a0cde24d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz8y7Jh7hwaK",
        "outputId": "8c0d9953-264f-4990-83e5-a91bf20a7b06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sumarized text: In this video, the speaker welcomes viewers to participate in an English speaking activity. The activity involves having a dialogue between the speaker and the viewer, where the viewer responds to the speaker's line of dialogue. The dialogue takes place in a store between a customer and a cashier. The cashier makes small talk with the customer, who has a question about the price of a product. The cashier apologizes for the confusion and fixes the incorrect price, and the customer pays with a credit card. The speaker\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "openai.api_key = ''\n",
        "\n",
        "def generate(prompt):\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            engine = 'gpt-3.5-turbo-instruct',\n",
        "            prompt = \"please summarize this text for me - \"+prompt,\n",
        "            max_tokens = 100\n",
        "        )\n",
        "\n",
        "        return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        print(\"Error: \", e)\n",
        "        return None\n",
        "\n",
        "generated = generate(text)\n",
        "print(\"Sumarized text:\",generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NxugxSjh3BH"
      },
      "source": [
        "# Code 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vqf4WV-h6ny",
        "outputId": "d59c6b27-27b4-455a-a637-399b35972aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-44l1bbea\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-44l1bbea\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=0cdcc28929bf3f33f42c349c5eb1840053ab7a990b749a9fac823ee6fc944012\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6_xj2lt0/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.6.0\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
            "  Downloading rapidfuzz-3.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.3 rapidfuzz-3.6.2\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KH44wA5iAV1",
        "outputId": "9e08e43e-f2f9-4167-bba6-07b4248a42f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "8w3UCLSdiBqC",
        "outputId": "8e9f7892-f4e7-40eb-e355-731e5afb9756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.6.2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a7c3f239-0afd-4a5f-bb88-7e38a4259477\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a7c3f239-0afd-4a5f-bb88-7e38a4259477\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving OWAISI.mp4 to OWAISI (1).mp4\n",
            "Video uploaded successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribed Text:  So let me ask this question. When it comes to interpretation of non-Hindu religions in India under law or in any of the Islamic seminaries, which book, which traces its origins to India is relied upon for interpretation of either Islamic law or Christian canon law? I am trying to ask myself the simple question since you are saying, I am using the word fatwa as a legal finding, a judicial finding, not in the negative sense. It is an advisory. Exactly. No problem. It is an advisory. So we are inviting a certain advisory. So the question is, which book do you find in your interpretation of India? My point is, everything that relates to Islam necessarily comes from a book and commentaries which do not originate in India. Could that be a correct statement to make? You are absolutely wrong. Oh, please say it. You don't know. Sahih al-Bukhari was author to India. Do you know Fafate wa Alam giri? Go to Alam giri? Go to Alam giri? So you use Fafate wa Alam giri to actually listen to where was Fafate wa Alam giri written? No, no, no. The question is, when you issue a Fafate wa Alam giri, do you use the Quran? Are you, are you, are you, are you, are you, are you, are you, are you, are you, are you, are you, are you, are you, are you, are you, are you, are you, are you, are you, you are, are you, are you, are you, are you, are you, are you, are you, are you, are you mulliter? I do not have a principle. I do not have a principle which we need. Should we express the principles for this or this commission? You know, I can relate to my view on this. Let me rewind it this way. To what the question is is by you? Let me put it in the other group. Okay. Come on, let me write it once again. Come on, tell me you have this. When it is, Sunna is hadith, then you have schools of thought, right? Hanuffy, Shafai, Malaki, Fee, then you have Fatawai alam, Giridhya, so many books. So, these schools of thought, what is the basis of the schools of thought? Is this the question? Every religion, every school of thought. Right. Basically, the audience understood the question. Okay. No, no, yes please. Fantastic. Right. Majority of Indian Muslims are Hanuffees. Okay. We follow Fatawai alam, Giridhya. Okay. And that protection, where it comes from, Article 26. Okay. Isn't it? And what is the basis of Fatawai alam, Giridhya? Fatawai alam, Giridhya is the opinion of the Islamic scholars who are born in India based on what? Based on Khuran, Sunna, and also advice. Also, also on the CA. So, since you represent a significant portion of Hyderabad, which has a significant Muslim population, which Hyderabad Muslim according to you is going to be affected by the CA. And why? Legally. When I... Not politically. Now listen to me. When I said, all three are South Indians. You said, I am an Indian from South. So, now let me retell you that any law which is passed, which is unconstitutional, which goes against the basis structure of the Constitution, it will affect every Indian. Right. And the respective of Hyderabad Hindu, Hyderabad Muslim, or Hyderabad Christian, that is the first answer. Secondly, why do you oppose CWA because in the 70s of our Indian Lok Sabah, not a single law has been made on the basis of religion. This has been done. It, in my opinion, and in the opinion of many legal luminaries, which you will again ask which name, is that it violates right to equality. Fourthly, this country cannot have two principles of citizenship. Fifth, about CWA, it is discriminatory, and it is... It violates Article 14 of equality because in Assam, NRC has been done. Nineteen lakh people, names did not come in the Assam, NRC. Out of that, only five lakh Muslims, the BJP intends to give citizenship to all those non-Muslims, and not to the Muslims. Why, again, all of them are illegal migrants because they have been come. Isn't that a violation of Article 14? And last point, CWA has to be looked to the prism of NPR and NRC. Because it relates to the citizenship act, these are the rules which were framed when atal Bihari Vajpaye was in power. That is why we oppose CWA, NPR and RSC, and please don't exclude me from your thought of India. So I am assuming that you are equally for Amidya Muslims from Pakistan for the entry into India. Is that the position? I am saying you remove the word religious minorities and bring everyone. So who's stopping you? So here's my question. Yes, I'm so sorry. The treatment that Razakar's under the Nizam, meet it out to Hindus and Hyderabad, the Pinsley state is the same treatment. No, you are jumping from CWA. Look, look, my answer has touched a runner, Vinny. I know, I can see, my answer has touched a runner, Vinny. Take me. Now, look at your thought process. I am not from CWA, you can drink whatever you want. No, no, I am not. From CWA, from CWA, you have jumped to Razakar. My father has told you, I have, no, listen to me. I have told you. You are the moderator from all the way. No, no, no. I am the staff leader. I am asking you a question. You are trying to become another subraman Swami to never happen in his life. I agree that there can never be another doctor Swami, and I don't ask about to be him as well. So, let me just ask this question. You are so sorry, why are you so sorry? I am sorry, sir. You are so sorry, sir. I have come to this program because I know all the people are coming. No, appreciate your guts. No, no. Sir, here's my thing. One to be fair to the audience. I think the audience has been fairly open to both points of view. Okay, your question. My question is that what the treatment Razakar has done with Hyderabad Indian was that there is a specific persecution based on religion. When the problem is the same religion, then why can't the solution's basis be religion? This is a little bit of a problem. That's why it can't be. That's why it can't be. Because there is no religion of India. Okay. It's not the religion of India. It's not the religion of India. The people who are dying are not the religion of India. You know, I don't know you. You are the love of Pakistan. I don't know you. You are the love of Pakistan. You are the love of the Lord. Yes. You are the only one who can give me the blessing. I see. I mean, I am the love of India. And we are always going to be there. Right. The question of the persecution based on the persecution. Who is the king of the persecution? Who is the king of the persecution? Who is the king of the persecution? Let's ask this question. Recognize persecution, but ignore the cause of the persecution is a solution. Persecution is persecution. Now, explain that to me. Please. Please. If any Hindu comes from Pakistan, India becomes a refugee, then it's not his fault. It's a refugee that can be formed when he is persecuted. Sir. And this is a point. Tell me the rules. Yes. Now, define the rules. What is the definition of persecution? If he is not defining the religious persecution, then you can see the documents. I don't know. I don't know. I don't know. I don't know. He comes from Pakistan, he comes from Afghanistan, he comes from Bangladesh, he comes from many countries. Yes. How do you know? Why are you making laws on religion? Why are you doing this? This law is the right to equality. If someone enters the society, then law is unconstitutional. He is a man and he is a man. You can't enter between the laws of the law. Thank you. I understand. That's your understanding of the constitution. And I understand you are no more a lawyer. I swear with you. Okay.\n",
            "Summary: This will be very helpful. One of the factors that you have been taking up is this. These are things which we always should be on the side of caution. Dear friends,\n"
          ]
        }
      ],
      "source": [
        "!pip install jiwer\n",
        "import os\n",
        "from jiwer import wer\n",
        "import openai\n",
        "\n",
        "openai.api_key = ''\n",
        "\n",
        "# Define a function to transcribe video and summarize the text\n",
        "def transcribe_and_summarize(video_path):\n",
        "    try:\n",
        "        import whisper\n",
        "        model = whisper.load_model(\"base\")\n",
        "        result = model.transcribe(video_path)\n",
        "        transcribed_text = result['text']\n",
        "        print(\"Transcribed Text:\", transcribed_text)\n",
        "\n",
        "        # Call the summarization function\n",
        "        summary = generate(transcribed_text)\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(\"Error transcribing video and summarizing text:\", e)\n",
        "        return None\n",
        "\n",
        "# Function to generate summary using OpenAI\n",
        "def generate(prompt):\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            engine='gpt-3.5-turbo-instruct',\n",
        "            prompt=\"please summarize this text for me - \" + prompt,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        print(\"Error: \", e)\n",
        "        return None\n",
        "\n",
        "# Upload .mp4 file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the path of the uploaded file\n",
        "uploaded_file_path = next(iter(uploaded))\n",
        "\n",
        "# Rename the file to \"uploaded_video.mp4\"\n",
        "os.rename(uploaded_file_path, \"OWAISI.mp4\")\n",
        "\n",
        "# Check if the file is an .mp4 file\n",
        "if uploaded_file_path.endswith('.mp4'):\n",
        "    video_path = \"OWAISI.mp4\"\n",
        "    print(\"Video uploaded successfully.\")\n",
        "\n",
        "    # Call the function to transcribe and summarize\n",
        "    summary = transcribe_and_summarize(video_path)\n",
        "    if summary:\n",
        "        print(\"Summary:\", summary)\n",
        "    else:\n",
        "        print(\"Failed to generate summary.\")\n",
        "else:\n",
        "    print(\"Please upload a valid .mp4 file.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8NxvrPViJt8"
      },
      "source": [
        "Video to text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "XyPa6UURFGYt",
        "outputId": "0034a5e5-007b-409d-b72c-95ce46175b93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.6.2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7c473b4c-a894-4ebc-9270-4688b3f30981\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7c473b4c-a894-4ebc-9270-4688b3f30981\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving OWAISI.mp4 to OWAISI (1).mp4\n",
            "Video uploaded successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribed Text:  So let me ask this question. When it comes to interpretation of non-Hindu religions in India under law or in any of the Islamic seminaries, which book, which traces its origins to India is relied upon for interpretation of either Islamic law or Christian canon law? I am trying to ask myself the simple question since you are saying, I am using the word fatwa as a legal finding, a judicial finding, not in the negative sense. It is an advisory. Exactly. No problem. It is an advisory. So we are inviting a certain advisory. So the question is, which book do you find in your interpretation of India? My point is, everything that relates to Islam necessarily comes from a book and commentaries which do not originate in India. Could that be a correct statement to make? You are absolutely wrong. Oh, please say it. You don't know. Sahih al-Bukhari was author to India. Do you know Fafate wa Alam giri? Go to Alam giri? Go to Alam giri? So you use Fafate wa Alam giri to actually listen to where was Fafate wa Alam giri written? No, no, no. The question is, when you issue a Fafate wa Alam giri, do you use the Quran? Are you, are you, are you, are you, are you, are you, are you, are you, are you, are with me or in your anchor? I am asking you. You are asking me. I am asking yourásingaimer funding. I'm asking you a second question. You heard, you heard me, I am answering you in a straightforward way. We'll listen to me. You have ru... Should I replace the question for you to understand? No, no, no. I have understood. I onlyıyor coming from answered. Please. Do you believe that the Islamic law is only Quran and Sunnah? No. Go and absolutely wrong. Go ahead. Please. No, it is not. Right. It is Quran. Yeah. It is sunnah. Right. It is the traditional order. What was given? Then you have schools of thought, right? Hanuffy, Shafai, Malaki, Fee, then you have Fatawaih Alam Giridhya, there are so many books. So these schools of thought, what is the basis of the schools of thought? Every religion, every school of thought. Right. Basically, the audience understood the question. Okay. No, no, listen. Yes, please. Fantastic. Right. Majority of Indian Muslims are Hanuffy's. Okay. We follow Fatawaih Alam Giridh. Okay. And that protection, where it comes from. Article 26. Okay. Isn't it? And what is the basis of Fatawaih Alam Giridhya? Fatawaih Alam Giridhya is the opinion of the Islamic scholars who are born in India based on what? Based on Khuran and Sunnah. And also advice. Thank you. Also, also on the CA. So since you represent a significant portion of Hyderabad, which has a significant Muslim population, which Hyderabad is Muslim according to you is going to be affected by the CA. And why? Because legally, when I listen to me, when I said all three are South Indians, you said, I am an Indian from South. So now, let me tell you that any law which is passed, which is unconstitutional, which goes against the basic structure of the constitution, it will affect every Indian irrespective of Hyderabad Hindu, Hyderabad Muslim or Hyderabad Christian, that is the first answer. Right. Why do you oppose CWA? Because in the 70s of our Indian Lok Sabha, not a single law has been made on the basis of religion. This has been done. It, in my opinion, and in the opinion of many legal luminaries, which you will again ask which name, is that it violates right to equality. Fourthly, this country cannot have two principles of citizenship. Fifth, about CWA, it is discriminatory and it is, it violates article 14 of equality, because in Assam, NRC has been done. Nineteen lakh people, names did not come in the Assam, NRC. Out of that, only five lack of Muslims. The BJP intends to give citizenship to all those non-Muslims and not to the Muslims. Why? Again, all of them are illegal migrants because they have been come. And the election article 14, and last point, CWA has to be looked to the prism of NPR and NRC. Because it relates to citizenship act. These are the rules which were framed when Atal Bihari Vajpaye was in power. That is why we oppose CWA, NPR and RSC, and please don't exclude me from your thought of India. So I am assuming that you are equally for Amidya Muslims from Pakistan for their entry into India. Is that the position? I am saying you remove the word religious minorities and bring everyone. Who is stopping you? So here is my question. Yes, I am, which if I am so sorry. The treatment that Razakars under the Nizam, meet out to Hindus and Hyderabad, the Pinsley state is the same treatment. No, you are jumping from CWA. Look, my answer has touched a runner, Vinny. I know, I know, my answer has touched a runner, Vinny. Take me. Now look at your thought process. I am not there. From CWA, you can drink water if you want. No, no, no. From CWA, from CWA, you have jumped to Razakars. My point has told you, I have told you. No, listen to me. I have told you. No, no, no, no. I am the staff leader of the moderator. You are trying to become another subrimineist who will ever happen in his life. I agree that there can never be another doctor Swami. And I don't ask about to be here as well. So, let me just ask this question. You are so afraid of questions. I am afraid of questions. By chance, sir. You are afraid of questions. I have come to this program because I know, I am a complete arousine. No, I appreciate your guts. Absolutely. No, no. Sir, here is my thing. One to be fair to the audience. I think the audience, I will say. I will say. I think the audience has been fairly open to both points of view. What do you say? Your question is. The treatment that was done with the Hinduism in Pakistan is the same. Therefore, there is a specific persecution which is based on religion. When the problem is the same religion, then why can't the solution of the solution be the same? That is why it can't be. That is why it can't be. Because there is no religion of India. Okay. It is not the religion of India. I am not the religion of India. You know, I don't love the great love of Pakistan. I don't love Pakistan. I love Pakistan. I love Afghanistan. I don't love Bangladesh. I see. I love India and always will always be there. The question of the question of the situation. Who is the Lord of the Christian? The Lord of the Christian. Let's ask this question. Recognize persecution. But ignore the cause of the persecution is the solution. Persecution is persecution. Now explain that to me. Listen to me. Please. If someone comes from India and becomes a refugee in India, then you are not able to refuse. You can become a refugee when you are persecuted. Sir. Tell me the rules. Now define the rules. What is the persecution? If he is not defining the religious persecution, then you can see the documents. I don't know. I don't know. I don't know. Pakistan is a Hindu. It is from Afghanistan. How do you know? How do you become a refugee when you are a refugee? You are a refugee. If someone comes from the right or the left, then you are an unconstitutional. You are a man and you are a man. You can't do the law in between your two. Thank you. I understand. That's your understanding of the constitution. And I understand you are no moral lawyer. I understand.\n"
          ]
        }
      ],
      "source": [
        "!pip install jiwer\n",
        "import os\n",
        "from jiwer import wer\n",
        "\n",
        "# Function to transcribe video to text\n",
        "def transcribe_video_to_text(video_path):\n",
        "    try:\n",
        "        import whisper\n",
        "        model = whisper.load_model(\"base\")\n",
        "        result = model.transcribe(video_path)\n",
        "        return result['text']\n",
        "    except Exception as e:\n",
        "        print(\"Error transcribing video to text:\", e)\n",
        "        return None\n",
        "\n",
        "# Upload .mp4 file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the path of the uploaded file\n",
        "uploaded_file_path = next(iter(uploaded))\n",
        "\n",
        "# Rename the file to \"uploaded_video.mp4\"\n",
        "os.rename(uploaded_file_path, \"OWAISI.mp4\")\n",
        "\n",
        "# Check if the file is an .mp4 file\n",
        "if uploaded_file_path.endswith('.mp4'):\n",
        "    video_path = \"OWAISI.mp4\"\n",
        "    print(\"Video uploaded successfully.\")\n",
        "\n",
        "    # Call the function to transcribe video to text\n",
        "    transcribed_text = transcribe_video_to_text(video_path)\n",
        "    if transcribed_text:\n",
        "        print(\"Transcribed Text:\", transcribed_text)\n",
        "    else:\n",
        "        print(\"Failed to transcribe video to text.\")\n",
        "else:\n",
        "    print(\"Please upload a valid .mp4 file.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb5fJgdcFFn8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34u2u8y7iPkJ"
      },
      "source": [
        "Text to summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsLJJacviQ-s"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = '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'\n",
        "\n",
        "# Function to generate summary using OpenAI\n",
        "def generate_summary(prompt):\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            engine='gpt-3.5-turbo-instruct',\n",
        "            prompt=\"please summarize this text for me - \" + prompt,\n",
        "            max_tokens=100\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        print(\"Error generating summary:\", e)\n",
        "        return None\n",
        "\n",
        "# Assuming you have the transcribed_text variable containing the text from the video\n",
        "transcribed_text = \"Text from the video\"  # Replace this with the actual transcribed text\n",
        "\n",
        "# Call the function to generate summary\n",
        "summary = generate_summary(transcribed_text)\n",
        "if summary:\n",
        "    print(\"Summary:\", summary)\n",
        "else:\n",
        "    print(\"Failed to generate summary.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
